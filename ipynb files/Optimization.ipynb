{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-26T17:28:40.942253Z",
     "start_time": "2022-03-26T17:28:29.071444Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T13:52:39.933610Z",
     "start_time": "2022-06-03T13:52:39.927023Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "from numpy.random import randint\n",
    "from numpy.random import rand\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "sys.path.append(\"./src/\")\n",
    "from filter2 import convert, filter2_run\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T13:52:40.105788Z",
     "start_time": "2022-06-03T13:52:40.100556Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def df_to_fasta(df, path):\n",
    "    lines = []\n",
    "    df.apply(lambda row: lines.append(f\">{row['tag']}\\n{row['data']}\\n\"),axis=1)\n",
    "    with open(path,'w') as file:\n",
    "        file.write(''.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T13:52:41.025169Z",
     "start_time": "2022-06-03T13:52:41.020671Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class DotDict(dict):\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T13:52:47.776293Z",
     "start_time": "2022-06-03T13:52:47.772203Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "experiment = \"O.sativa_Test\"\n",
    "experiment_dir = \"Experiment\"\n",
    "temp_path = f\"{experiment_dir}/{experiment}/Temp\"\n",
    "result_path = f\"{experiment_dir}/{experiment}/Result\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T13:50:04.790769Z",
     "start_time": "2022-06-03T13:50:04.724796Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self, x0,num_dimensions):\n",
    "        self.num_dimensions = num_dimensions\n",
    "        self.position_i=[]          # particle position\n",
    "        self.velocity_i=[]          # particle velocity\n",
    "        self.pos_best_i=[]          # best position individual\n",
    "        self.err_best_i=-1          # best error individual\n",
    "        self.err_i=-1               # error individual\n",
    "\n",
    "        for i in range(0,num_dimensions):\n",
    "            self.velocity_i.append(random.uniform(-1,1))\n",
    "            self.position_i.append(x0[i])\n",
    "\n",
    "    # evaluate current fitness\n",
    "    def evaluate(self, costFunc):\n",
    "        self.err_i=costFunc(self.position_i)\n",
    "\n",
    "        # check to see if the current position is an individual best\n",
    "        if self.err_i < self.err_best_i or self.err_best_i==-1:\n",
    "            self.pos_best_i=self.position_i\n",
    "            self.err_best_i=self.err_i\n",
    "\n",
    "    # update new particle velocity\n",
    "    def update_velocity(self, pos_best_g):\n",
    "        w = 0.7       # constant inertia weight (how much to weigh the previous velocity)\n",
    "        c1 = 1.4        # cognative constant\n",
    "        c2 = 1.4        # social constant\n",
    "\n",
    "        for i in range(0, self.num_dimensions):\n",
    "            r1 = random.random()\n",
    "            r2 = random.random()            \n",
    "            vel_cognitive = c1*r1*(self.pos_best_i[i]-self.position_i[i])\n",
    "            vel_social = c2*r2*(pos_best_g[i]-self.position_i[i])\n",
    "            self.velocity_i[i] = w*self.velocity_i[i]+vel_cognitive+vel_social\n",
    "\n",
    "    # update the particle position based off new velocity updates\n",
    "    def update_position(self):\n",
    "        for i in range(0, self.num_dimensions):\n",
    "            self.position_i[i] = self.position_i[i] + self.velocity_i[i]\n",
    "\n",
    "            # adjust maximum position if necessary\n",
    "            if self.position_i[i]> 1:\n",
    "                self.position_i[i]= 1\n",
    "\n",
    "            # adjust minimum position if neseccary\n",
    "            if self.position_i[i] < 0:\n",
    "                self.position_i[i] = 0\n",
    "\n",
    "\n",
    "def evaluation(particle):\n",
    "    particle.evaluate(cost_function)\n",
    "    return particle\n",
    "\n",
    "\n",
    "class PSO:\n",
    "    def __init__(self, costFunc, num_particles, maxiter, num_dimensions):\n",
    "        err_best_g = -1\n",
    "        pos_best_g = []        \n",
    "        swarm = []\n",
    "                \n",
    "        swarm = []\n",
    "        for i in range(0, num_particles):\n",
    "            x0 = [random.uniform(0, 1) for j in range(num_dimensions)]\n",
    "            swarm.append(Particle(x0, num_dimensions))            \n",
    "        \n",
    "        ############## main loop #######################\n",
    "        for i in range(maxiter):                       \n",
    "            counter = 0 \n",
    "            #for particle in process_map(evaluation, swarm, tqdm_class=tqdm, max_workers=22, chunksize=5):\n",
    "            for s in swarm:\n",
    "                particle = evaluation(s)\n",
    "                if particle.err_i < err_best_g or err_best_g == -1:\n",
    "                    pos_best_g=list(particle.position_i)\n",
    "                    err_best_g=float(particle.err_i)                \n",
    "                swarm[counter] = particle\n",
    "                counter += 1\n",
    "            \n",
    "            # cycle through swarm and update velocities and position                        \n",
    "            for j in range(0,num_particles):\n",
    "                swarm[j].update_velocity(pos_best_g)\n",
    "                swarm[j].update_position()                        \n",
    "            print(err_best_g)                        \n",
    "            print(costFunc(pos_best_g, show=True))\n",
    "        # print final results        \n",
    "        print(pos_best_g)\n",
    "        print(err_best_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T15:03:51.382142Z",
     "start_time": "2022-05-31T15:03:51.355599Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Individual:\n",
    "    def __init__(self, costFunc, bounds, num_dimensions, r_mut, new=True):\n",
    "        self.num_dimensions = num_dimensions\n",
    "        self.bounds = bounds    \n",
    "        self.r_mut = r_mut\n",
    "        self.costFunc = costFunc\n",
    "        if(new):\n",
    "            self.random_solution()\n",
    "            self.evaluate()\n",
    "    \n",
    "    def copy(self):\n",
    "        clone = Individual(self.costFunc, self.bounds, self.num_dimensions, self.r_mut, new=False)\n",
    "        clone.position = self.position.copy()\n",
    "        clone.cost = self.cost\n",
    "        return clone\n",
    "    \n",
    "    def random_solution(self):\n",
    "        self.position = [random.uniform(bound[0], bound[1]) for bound in self.bounds]        \n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.cost = self.costFunc(self.position)        \n",
    "        \n",
    "    def mutation(self):                \n",
    "        for i in range(self.num_dimensions):\n",
    "            if rand() < self.r_mut:        \n",
    "                self.position[i] = random.uniform(self.bounds[i][0], self.bounds[i][1])                        \n",
    "\n",
    "class Genetic_Algorithm:\n",
    "    def create_individual(self, inp):\n",
    "        return Individual(self.costFunc, self.bounds, self.num_dimensions, self.r_mut)\n",
    "    \n",
    "    def selection(self, scores, k=3):    \n",
    "        selection_ix = randint(len(self.pop))        \n",
    "        for ix in randint(0, len(self.pop), k-1):        \n",
    "            if scores[ix] < scores[selection_ix]:\n",
    "                selection_ix = ix\n",
    "        return self.pop[selection_ix]\n",
    "    \n",
    "    def crossover_one_point(self, p1, p2):    \n",
    "        c1 = p1.copy()\n",
    "        c2 = p2.copy()            \n",
    "        if rand() < self.r_cross:                 \n",
    "            pt = randint(1, len(p1.position)-2)                    \n",
    "            c1.position = p1.position[:pt] + p2.position[pt:]\n",
    "            c2.position = p2.position[:pt] + p1.position[pt:]                \n",
    "        return [c1, c2]\n",
    "    \n",
    "    def crossover_uniform(self, p1, p2):    \n",
    "        c1 = p1.copy()\n",
    "        c2 = p2.copy()            \n",
    "        for i in range(len(p1.position)):\n",
    "            if(rand() < 0.5):\n",
    "                c1.position[i] = p2.position[i] \n",
    "                c2.position[i] = p1.position[i]                 \n",
    "        return [c1, c2]\n",
    "    \n",
    "    def apply_operations(self, index):        \n",
    "        p1 = self.selected[index]        \n",
    "        p2 = self.selected[index+1]      \n",
    "        if(rand() > 0.5):\n",
    "            c1, c2 = self.crossover_one_point(p1, p2)                        \n",
    "        else:\n",
    "            c1, c2 = self.crossover_uniform(p1, p2)                        \n",
    "        c1.mutation()\n",
    "        c2.mutation()\n",
    "        c1.evaluate()\n",
    "        c2.evaluate()\n",
    "        return [c1, c2]\n",
    "\n",
    "    def __init__(self, costFunc, bounds, num_individual, maxiter, num_dimensions, r_cross, r_mut):                    \n",
    "        self.costFunc = costFunc\n",
    "        self.bounds = bounds\n",
    "        self.num_individual = num_individual\n",
    "        self.maxiter = maxiter\n",
    "        self.num_dimensions = num_dimensions\n",
    "        self.r_cross = r_cross\n",
    "        self.r_mut = r_mut\n",
    "        \n",
    "        best = self.create_individual(None)\n",
    "        \n",
    "        self.pop = []\n",
    "        for individual in process_map(self.create_individual, range(0,num_individual), tqdm_class=tqdm, max_workers=22, chunksize=5):\n",
    "            self.pop.append(individual)                        \n",
    "    \n",
    "        for gen in tqdm(range(maxiter)):\n",
    "            scores = [individual.cost for individual in self.pop]        \n",
    "            for individual in self.pop:\n",
    "                if individual.cost < best.cost:\n",
    "                    best = individual.copy()\n",
    "                    \n",
    "            self.selected = [self.selection(scores) for _ in range(num_individual)]        \n",
    "            self.pop = list()\n",
    "            for [p1, p2] in process_map(self.apply_operations, range(0, num_individual, 2), tqdm_class=tqdm, max_workers=22, chunksize=5):\n",
    "                self.pop.append(p1)\n",
    "                self.pop.append(p2)       \n",
    "            print(best.cost)\n",
    "            print(best.position)\n",
    "        return [best.cost, best.position]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T14:33:56.675253Z",
     "start_time": "2022-06-03T14:31:48.763144Z"
    }
   },
   "outputs": [],
   "source": [
    "level1 = pd.read_csv(f\"{result_path}/result_level1_filter.csv\")\n",
    "level1 = level1.apply(lambda row: convert(row), axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T14:04:14.939572Z",
     "start_time": "2022-06-03T14:04:14.932379Z"
    }
   },
   "outputs": [],
   "source": [
    "df = level1[level1['confidence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T12:14:43.014450Z",
     "start_time": "2022-06-01T12:14:43.001671Z"
    }
   },
   "outputs": [],
   "source": [
    "bounds = [        \n",
    "        (-1000,-999),#\"delta_g_min\": -1000,\n",
    "        (0, 1),#\"delta_g_max\": 0,\n",
    "        (19, 22),#\"hit_len_min\": 19,\n",
    "        (21, 26),#\"hit_len_max\": 24,\n",
    "        (0, 0.5),#\"hit_complementarity_percentage_min\": 0.3,\n",
    "        (0.5, 1),#\"hit_complementarity_percentage_max\": 1,\n",
    "        (0, 2),#\"number_of_terminal_structure_min\": 1,\n",
    "        (0, 6),#\"number_of_terminal_structure_max\": 1,\n",
    "        (0, 50),#\"boi_gc_content_min\": 20,\n",
    "        (50, 100),#\"boi_gc_content_max\": 80,\n",
    "        (0, 50),#\"num_of_linking_residues_min\": 5,\n",
    "        (20, 1000),#\"num_of_linking_residues_max\": 80,\n",
    "        (0, 50),#\"hit_gc_content_percentage_min\": 20,\n",
    "        (50, 100),#\"hit_gc_content_percentage_max\": 80,\n",
    "        (0, 1.5),#\"precursor_mfei_min\": 0.5,\n",
    "        (0.5, 5),#\"precursor_mfei_max\":3,\n",
    "        (0, 7),#\"border_line_mismatch_max\": 1,\n",
    "        (0, 7),#\"border_line_bulge_max\": 0,\n",
    "        (0, 7),#\"border_line_internal_max\": 0,\n",
    "        (0, 20),#\"total_num_of_nonmatching_positions\": 5,\n",
    "        (0, 20),#\"total_num_of_mismached_positions\": 5,\n",
    "        (0, 20),#\"total_num_of_positions_in_bulges_and_loops\": 3,\n",
    "        (0, 20),#\"max_allowed_mismatch_size_in_hit_region\": 2,\n",
    "        (0, 20),#\"max_allowed_bulge_size_in_hit_region\": 1,\n",
    "        (0, 20),#\"max_allowed_internal_loop_size_in_hit_region\": 0,\n",
    "        (0, 20),#\"max_allowed_hsbl_ssbl_size\": 4,\n",
    "        (0, 50),#\"minimum_required_clear_region\": 13,\n",
    "        (0, 10),#\"acceptable_num_for_hit_locations_in_bulges_or_loops\": 3,\n",
    "        (0, 10),#\"acceptable_num_for_unmatched_locations_in_hit_region\": 5,\n",
    "        (0, 1),#\"delete_if_mature_duplex_involvement_in_apical_loop\": \"yes\",\n",
    "        (0, 2),#\"border_line_structure_allowance\": \"1 end only\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T15:29:20.558813Z",
     "start_time": "2022-06-03T15:29:20.538336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence = set(['TGACAGAAGAGAGTGAGCAC',\n",
    "              'GCTCACTCTCTATCTGTCAGC',\n",
    "              'GCTCACTTCTCTCTCTGTCAGC',\n",
    "              'GCTCACTTCTCTTTCTGTCAGC',\n",
    "              'GCTCGCTCCTCTTTCTGTCAGC',\n",
    "              'TGCCTGGCTCCCTGTATGCCA',\n",
    "              'GCGTGCAAGGAGCCAAGCATG',\n",
    "              'GCGTGCACGGAGCCAAGCATA',\n",
    "              'GGAATGTTGTCTGGTTCAAGG',\n",
    "              'TCGGACCAGGCTTCATTCCCC',\n",
    "              'GGAATGTTGTCTGGCTCGGGG',\n",
    "              'GGAATGTTGTCTGGTCCGAG',\n",
    "              'GGAATGTTGTCTGGCTCGAGG',\n",
    "              'TGAAGCTGCCAGCATGATCTA',\n",
    "              'ATCATGCATGACAGCCTCATTT',\n",
    "              'TTCCACAGCTTTCTTGAACTT',\n",
    "              'GGTCAAGAAAGCTGTGGGAAG',\n",
    "              'CGACAGAAGAGAGTGAGCATA',\n",
    "              'GGTTTGTTGTCTGGCTCGAGG',\n",
    "              'TCGGACCAGGCTTCAATCCCT',\n",
    "              'GGATTGTTGTCTGGTTCAAGG',\n",
    "              'TGAAGCTGCCAGCATGATCTG',\n",
    "              'AGATCATGTTGCAGCTTCACT',\n",
    "              'TCGCTTGGTGCAGATCGGGAC',\n",
    "              'GATCCCGCCTTGCACCAAGTGAAT',\n",
    "              'TGGTGATAAGGGTGTAGCTCTG',\n",
    "              'TAGCCAAGGATGACTTGCCTG',\n",
    "              'TGAGTCGCTCTTATCACTCATG',\n",
    "              'GGATATTGGTGCGGTTCAATC',\n",
    "              'TGATTGAGCCGTGCCAATATC',\n",
    "              'TGTTGGCCCGGCTCACTCAGA',\n",
    "              'TGTTGGCTCGGCTCACTCAGA',\n",
    "              'GGAATGTTGGCTGGCTCGAGG',\n",
    "              'TCGGACCAGGCTTCATTCCTC',\n",
    "              'TCCAAAGGGATCGCATTGATCT',\n",
    "              'TCAGTGCAATCCCTTTGGAAT',\n",
    "              'CAGGGATGAGGCAGAGCATGG',\n",
    "              'CTGCACTGCCTCTTCCCTGGC',\n",
    "              'GCAGCACCATCAAGATTCAC',\n",
    "              'AGAATCTTGATGATGCTGCAT',\n",
    "              'AGGTATTGGCGTGCCTCAATC',\n",
    "              'GGATTGAGCCGCGTCAATATC',\n",
    "              'AAGCTCAGGAGGGATAGCGCC',\n",
    "              'CGCTATCTATCCTGAGCTCC',\n",
    "              'TCCACAGGCTTTCTTGAACTG',\n",
    "              'ATGGTTCAAGAAAGCCCATGGAAA',\n",
    "              'GCTAGAGGTGGCAACTGCATA',\n",
    "              'TGCAGTTGCTGCCTCAAGCTT',\n",
    "              'TTGCTGCCTCAAGCTTGCTGC',\n",
    "              'TAGGATTCAATCCTTGCTGCT',\n",
    "              'CAGCAAGAACTGGATCTTAAT',\n",
    "              'GTAATATACTAATCCGTGCAT',\n",
    "              'GTTGCACGGGTTTGTATGTTG',\n",
    "              'TAGCCAAGGATGATTTGCCTG',\n",
    "              'TGGCAAGTCTCCTCGGCTACC',\n",
    "              'TCTCCACAGGCTTTCTTGAACT',\n",
    "              'ATAGTTCAAGAAAGTCCTTGGAAA',\n",
    "              'TCTCTCTCTCCCTTGAAGGC',\n",
    "              'CTTCGGGGGAGGAGAGAAGC',\n",
    "              'AATCGACGGCCTCAGTCAGGG',\n",
    "              'CTGGCCGAGGCCGTCGATTCT',\n",
    "              'AGCTTCTGACAGCTGCAGTTTCTC',\n",
    "              'AGAAGCTGCAGCTGTCAGAAGCTC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T13:51:05.868633Z",
     "start_time": "2022-06-03T13:51:05.845413Z"
    }
   },
   "outputs": [],
   "source": [
    "def Blast(output, subject, query):\n",
    "    command = f'''makeblastdb -in {subject} -dbtype nucl -out ./{temp_path}/blastn_database'''\n",
    "    os.system(command)\n",
    "    command = f'''\n",
    "    blastn -query {query} \\\n",
    "    -out ./{temp_path}/blast_temp \\\n",
    "    -num_threads {mp.cpu_count()} \\\n",
    "    -db ./{temp_path}/blastn_database \\\n",
    "    -word_size 7 \\\n",
    "    -penalty -3 \\\n",
    "    -reward 2 \\\n",
    "    -gapopen 5 \\\n",
    "    -gapextend 2 \\\n",
    "    -outfmt '6 qseqid sseqid qstart qend sstart send qseq sseq evalue bitscore score length pident nident mismatch positive gapopen gaps ppos frames qframe sframe sstrand qcovs qcovhsp qlen slen'\n",
    "    '''\n",
    "    os.system(command)\n",
    "    \n",
    "    \n",
    "def getBlast(path):    \n",
    "    header = 'qseqid sseqid qstart qend sstart send qseq sseq evalue bitscore score length pident nident mismatch positive gapopen gaps ppos frames qframe sframe sstrand qcovs qcovhsp qlen slen'\n",
    "    df_blastn = pd.read_csv(path, sep='\\t', header=None)\n",
    "    df_blastn.columns = header.replace(\"  \",\" \").split(\" \")\n",
    "    df_blastn = df_blastn[df_blastn['sstrand'] == \"plus\"]    \n",
    "    df_blastn['Nonconformity'] = df_blastn['qlen'] - (abs(df_blastn['qend'] - df_blastn['qstart']) + 1) + df_blastn['gaps'] + df_blastn['mismatch']    \n",
    "    df_blastn = df_blastn[df_blastn['Nonconformity'] <= 0]\n",
    "    return df_blastn[\"qseq\"].unique()    \n",
    "    \n",
    "def cost_function(solution, alpha = 0.92 , beta=0.45, show=False):\n",
    "    sol = [bounds[i][0] + (solution[i] * (bounds[i][1] - bounds[i][0])) for i in range(0, len(bounds))]\n",
    "    deleted_type = [\"NO\", \"YES\"]\n",
    "    allwance_type = [\"NOT ACCEPTED\", \"1 END ONLY\", \"2 SIDE\"]\n",
    "    config = {\n",
    "        \"delta_g_min\": sol[0],\n",
    "        \"delta_g_max\": sol[1],\n",
    "        \"hit_len_min\": round(sol[2]),\n",
    "        \"hit_len_max\": round(sol[3]),\n",
    "        \"hit_complementarity_percentage_min\": sol[4],\n",
    "        \"hit_complementarity_percentage_max\": sol[5],\n",
    "        \"number_of_terminal_structure_min\": round(sol[6]),\n",
    "        \"number_of_terminal_structure_max\": round(sol[7]),\n",
    "        \"boi_gc_content_min\": round(sol[8]),\n",
    "        \"boi_gc_content_max\": round(sol[9]),\n",
    "        \"num_of_linking_residues_min\": round(sol[10]),\n",
    "        \"num_of_linking_residues_max\": round(sol[11]),\n",
    "        \"hit_gc_content_percentage_min\": round(sol[12]),\n",
    "        \"hit_gc_content_percentage_max\": round(sol[13]),\n",
    "        \"precursor_mfei_min\": sol[14],\n",
    "        \"precursor_mfei_max\": sol[15],\n",
    "        \"border_line_mismatch_max\": round(sol[16]),\n",
    "        \"border_line_bulge_max\": round(sol[17]),\n",
    "        \"border_line_internal_max\": round(sol[18]),\n",
    "        \"total_num_of_nonmatching_positions\": round(sol[19]),\n",
    "        \"total_num_of_mismached_positions\": round(sol[20]),\n",
    "        \"total_num_of_positions_in_bulges_and_loops\": round(sol[21]),\n",
    "        \"max_allowed_mismatch_size_in_hit_region\": round(sol[22]),\n",
    "        \"max_allowed_bulge_size_in_hit_region\": round(sol[23]),\n",
    "        \"max_allowed_internal_loop_size_in_hit_region\": round(sol[24]),\n",
    "        \"max_allowed_hsbl_ssbl_size\": round(sol[25]),\n",
    "        \"minimum_required_clear_region\": round(sol[26]),\n",
    "        \"acceptable_num_for_hit_locations_in_bulges_or_loops\": round(sol[27]),\n",
    "        \"acceptable_num_for_unmatched_locations_in_hit_region\": round(sol[28]),\n",
    "        \"delete_if_mature_duplex_involvement_in_apical_loop\": deleted_type[round(sol[29])],\n",
    "        \"border_line_structure_allowance\": allwance_type[round(sol[30])]\n",
    "    }    \n",
    "    config = DotDict(config)\n",
    "    result = filter2_run(level1.copy(), config)\n",
    "    if(result.shape[0] == 0):\n",
    "        return 10**6\n",
    "    \n",
    "    subject = f\"./{temp_path}/filter_level2_temp.csv\"\n",
    "    output  = f\"./{temp_path}/blast_temp\"\n",
    "    query   = f\"./{temp_path}/BLASTn_O.sativa.fasta\"    \n",
    "    \n",
    "    result['tag'] = (result['seq name'] + result['ct name'])        \n",
    "    result['data'] = result['hit seq']\n",
    "    df_to_fasta(result[['tag', 'data']], subject)        \n",
    "    \n",
    "    Blast(output=output, query=query, subject=subject)\n",
    "    out = set(getBlast(output))    \n",
    "    missing = 1000 - len(out)    \n",
    "    find_conf = len(out.intersection(confidence))    \n",
    "    missing_conf = 1000 - find_conf\n",
    "    fp = len(set(result['hit seq']) - out)\n",
    "    if(show):\n",
    "        print(f'conf: {find_conf}, find: {len(out)}, fp: {fp}')\n",
    "        print(config)\n",
    "        print(solution)\n",
    "    return missing * alpha + (1-alpha) * fp + missing_conf * beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T14:29:15.364656Z",
     "start_time": "2022-06-03T14:29:15.342519Z"
    }
   },
   "outputs": [],
   "source": [
    "####################################### new ######################################\n",
    "def Blast(output, subject, query):\n",
    "    command = f'''makeblastdb -in {subject} -dbtype nucl -out ./{temp_path}/blastn_database'''\n",
    "    os.system(command)\n",
    "    command = f'''\n",
    "    blastn -query {query} \\\n",
    "    -out ./{temp_path}/blast_temp \\\n",
    "    -num_threads {mp.cpu_count()} \\\n",
    "    -db ./{temp_path}/blastn_database \\\n",
    "    -word_size 7 \\\n",
    "    -penalty -3 \\\n",
    "    -reward 2 \\\n",
    "    -gapopen 5 \\\n",
    "    -gapextend 2 \\\n",
    "    -outfmt '6 qseqid sseqid qstart qend sstart send qseq sseq evalue bitscore score length pident nident mismatch positive gapopen gaps ppos frames qframe sframe sstrand qcovs qcovhsp qlen slen'\n",
    "    '''\n",
    "    os.system(command)\n",
    "    \n",
    "    \n",
    "def getBlast(path):    \n",
    "    header = 'qseqid sseqid qstart qend sstart send qseq sseq evalue bitscore score length pident nident mismatch positive gapopen gaps ppos frames qframe sframe sstrand qcovs qcovhsp qlen slen'\n",
    "    df_blastn = pd.read_csv(path, sep='\\t', header=None)\n",
    "    df_blastn.columns = header.replace(\"  \",\" \").split(\" \")\n",
    "    df_blastn = df_blastn[df_blastn['sstrand'] == \"plus\"]    \n",
    "    df_blastn['Nonconformity'] = df_blastn['qlen'] - (abs(df_blastn['qend'] - df_blastn['qstart']) + 1) + df_blastn['gaps'] + df_blastn['mismatch']    \n",
    "    df_blastn = df_blastn[df_blastn['Nonconformity'] <= 0]\n",
    "    return df_blastn[\"qseq\"].unique()    \n",
    "    \n",
    "def cost_function(solution, alpha = 0.925, show=False):\n",
    "    sol = [bounds[i][0] + (solution[i] * (bounds[i][1] - bounds[i][0])) for i in range(0, len(bounds))]\n",
    "    deleted_type = [\"NO\", \"YES\"]\n",
    "    allwance_type = [\"NOT ACCEPTED\", \"1 END ONLY\", \"2 SIDE\"]\n",
    "    config = {\n",
    "        \"delta_g_min\": sol[0],\n",
    "        \"delta_g_max\": sol[1],\n",
    "        \"hit_len_min\": round(sol[2]),\n",
    "        \"hit_len_max\": round(sol[3]),\n",
    "        \"hit_complementarity_percentage_min\": sol[4],\n",
    "        \"hit_complementarity_percentage_max\": sol[5],\n",
    "        \"number_of_terminal_structure_min\": round(sol[6]),\n",
    "        \"number_of_terminal_structure_max\": round(sol[7]),\n",
    "        \"boi_gc_content_min\": round(sol[8]),\n",
    "        \"boi_gc_content_max\": round(sol[9]),\n",
    "        \"num_of_linking_residues_min\": round(sol[10]),\n",
    "        \"num_of_linking_residues_max\": round(sol[11]),\n",
    "        \"hit_gc_content_percentage_min\": round(sol[12]),\n",
    "        \"hit_gc_content_percentage_max\": round(sol[13]),\n",
    "        \"precursor_mfei_min\": sol[14],\n",
    "        \"precursor_mfei_max\": sol[15],\n",
    "        \"border_line_mismatch_max\": round(sol[16]),\n",
    "        \"border_line_bulge_max\": round(sol[17]),\n",
    "        \"border_line_internal_max\": round(sol[18]),\n",
    "        \"total_num_of_nonmatching_positions\": round(sol[19]),\n",
    "        \"total_num_of_mismached_positions\": round(sol[20]),\n",
    "        \"total_num_of_positions_in_bulges_and_loops\": round(sol[21]),\n",
    "        \"max_allowed_mismatch_size_in_hit_region\": round(sol[22]),\n",
    "        \"max_allowed_bulge_size_in_hit_region\": round(sol[23]),\n",
    "        \"max_allowed_internal_loop_size_in_hit_region\": round(sol[24]),\n",
    "        \"max_allowed_hsbl_ssbl_size\": round(sol[25]),\n",
    "        \"minimum_required_clear_region\": round(sol[26]),\n",
    "        \"acceptable_num_for_hit_locations_in_bulges_or_loops\": round(sol[27]),\n",
    "        \"acceptable_num_for_unmatched_locations_in_hit_region\": round(sol[28]),\n",
    "        \"delete_if_mature_duplex_involvement_in_apical_loop\": deleted_type[round(sol[29])],\n",
    "        \"border_line_structure_allowance\": allwance_type[round(sol[30])]\n",
    "    }    \n",
    "    config = DotDict(config)\n",
    "    #result = filter2_run(df.copy(), config)\n",
    "    result = df.copy()\n",
    "    if(result.shape[0] == 0):\n",
    "        return 10**6\n",
    "    \n",
    "    subject = f\"./{temp_path}/filter_level2_temp.csv\"\n",
    "    output  = f\"./{temp_path}/blast_temp\"\n",
    "    query   = f\"./{temp_path}/BLASTn_O_Sativa\"    \n",
    "    \n",
    "    result['tag'] = (result['seq name'] + result['ct name'])        \n",
    "    result['data'] = result['hit seq']\n",
    "    df_to_fasta(result[['tag', 'data']], subject)        \n",
    "    \n",
    "    Blast(output=output, query=query, subject=subject)\n",
    "    out = set(getBlast(output))                \n",
    "    fp = len(set(result['hit seq']) - out)\n",
    "    if(show):\n",
    "        print(f'conf:{len(out)}, fp: {fp}')\n",
    "        print(config)\n",
    "        print(solution)\n",
    "    return -1 * (len(out) * alpha ) + (1-alpha) * fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T14:27:57.405709Z",
     "start_time": "2022-06-03T14:23:38.496594Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PSO(cost_function , num_particles = 250, maxiter=100, num_dimensions=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_junction_distance(data, dist, thresh_bulge, thresh_loop):\n",
    "    distance = []\n",
    "    for d in data:\n",
    "        if(d['type'] == 'loop'):\n",
    "            size = float(eval(d['size']))\n",
    "            if(size >= thresh_loop):                \n",
    "                distance.append(float(d['dist']))\n",
    "        if(d['type'] == 'bulge'):\n",
    "            if(float(d['size']) >= thresh_bulge):\n",
    "                distance.append(float(d['dist']))\n",
    "    distance.append(dist)\n",
    "    return min(distance)\n",
    "\n",
    "\n",
    "def _convert_hr(x):\n",
    "    out = []\n",
    "    x = eval(x)\n",
    "    for item in x:                \n",
    "        out.append({'type':item.split(\"=\")[0],\n",
    "                           'dist': item.split(\"dist:\")[1].split(', ')[0],\n",
    "                           'size': item.split(\"size:\")[1]})\n",
    "    return out\n",
    "\n",
    "config = {'delta_g_min': -999,\n",
    "          'delta_g_max': 1,\n",
    "          'hit_len_min': 21,\n",
    "          'hit_len_max': 21,\n",
    "          'hit_complementarity_percentage_min': 0.5,\n",
    "          'hit_complementarity_percentage_max': 1.0,\n",
    "          'number_of_terminal_structure_min': 0,\n",
    "          'number_of_terminal_structure_max': 5,\n",
    "          'boi_gc_content_min': 45,\n",
    "          'boi_gc_content_max': 94, \n",
    "          'num_of_linking_residues_min': 5, \n",
    "          'num_of_linking_residues_max': 159,\n",
    "          'hit_gc_content_percentage_min': 37, \n",
    "          'hit_gc_content_percentage_max': 86,\n",
    "          'precursor_mfei_min': 0.87,\n",
    "          'precursor_mfei_max': 1.3695556794836854, \n",
    "          'border_line_mismatch_max': 0,\n",
    "          'border_line_bulge_max': 0,\n",
    "          'border_line_internal_max': 0,\n",
    "          'total_num_of_nonmatching_positions': 5,\n",
    "          'total_num_of_mismached_positions': 5,\n",
    "          'total_num_of_positions_in_bulges_and_loops': 2,\n",
    "          'max_allowed_mismatch_size_in_hit_region': 2,\n",
    "          'max_allowed_bulge_size_in_hit_region': 1,\n",
    "          'max_allowed_internal_loop_size_in_hit_region': 3,\n",
    "          'max_allowed_hsbl_ssbl_size': 2,\n",
    "          'minimum_required_clear_region': 0,\n",
    "          'acceptable_num_for_hit_locations_in_bulges_or_loops': 2,\n",
    "          'acceptable_num_for_unmatched_locations_in_hit_region': 5,\n",
    "          'delete_if_mature_duplex_involvement_in_apical_loop': 'YES',\n",
    "          'border_line_structure_allowance': 'NOT ACCEPTED'}\n",
    "\n",
    "\n",
    "df = level1.copy()\n",
    "\n",
    "'''\n",
    "effective_bulge_size_in_Hit_vicinity_regions = 6\n",
    "effective_internal_loop_size_in_Hit_vicinity_regions = 8\n",
    "\n",
    "df[\"distal\"] = df[\"distal distance\"].apply(lambda x : _convert_hr(x))\n",
    "df[\"proximal\"] = df[\"proximal distance\"].apply(lambda x : _convert_hr(x))\n",
    "\n",
    "\n",
    "def junc_distal(row):\n",
    "    return get_junction_distance(row['distal'], row['base structure corrected length'], effective_bulge_size_in_Hit_vicinity_regions, effective_internal_loop_size_in_Hit_vicinity_regions)      \n",
    "\n",
    "def junc_prox(row):\n",
    "    return get_junction_distance(row['proximal'], row['primary stem corrected length'], effective_bulge_size_in_Hit_vicinity_regions, effective_internal_loop_size_in_Hit_vicinity_regions)      \n",
    "\n",
    "df[\"Loop distal junction distance\"] = df[['distal','base structure corrected length']].apply(lambda row: junc_distal(row), axis=1)\n",
    "df[\"Loop proximal junction distance\"] = df[['proximal', 'primary stem corrected length']].apply(lambda row: junc_prox(row), axis=1)\n",
    "'''\n",
    "\n",
    "\n",
    "config = DotDict(config)\n",
    "result = filter2_run(df, config)\n",
    "    \n",
    "subject = f\"./{temp_path}/filter_level2_temp.csv\"\n",
    "output  = f\"./{temp_path}/blast_temp\"\n",
    "query   = f\"./{temp_path}/BLASTn_O.sativa.fasta\"    \n",
    "    \n",
    "result['tag'] = (result['seq name'] + result['ct name'])        \n",
    "result['data'] = result['hit seq']\n",
    "df_to_fasta(result[['tag', 'data']], subject)        \n",
    "    \n",
    "Blast(output=output, query=query, subject=subject)\n",
    "out = set(getBlast(output))    \n",
    "missing = 92 - len(out)    \n",
    "find_conf = len(out.intersection(confidence))    \n",
    "missing_conf = 33 - find_conf\n",
    "fp = len(set(result['hit seq']) - out)\n",
    "print(out.intersection(confidence))\n",
    "print()\n",
    "print()\n",
    "print(f'conf: {find_conf}, find: {len(out)}, fp: {fp}')\n",
    "print(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
