{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyC8IFwrWkag"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T16:45:08.750729Z",
     "start_time": "2023-01-06T16:45:03.306924Z"
    },
    "id": "16Duf9iWWkat"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version  2.9.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "from __future__ import division\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from numpy.random import randint\n",
    "from numpy.random import rand\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Input,Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D, BatchNormalization,LSTM,Bidirectional\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D,UpSampling1D, Conv1DTranspose,GaussianNoise \n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.regularizers import l2 , l1, l1_l2\n",
    "import tensorflow.keras.backend as kb\n",
    "print('keras version ', keras.__version__)\n",
    "\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T16:45:08.998920Z",
     "start_time": "2023-01-06T16:45:08.754957Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../src\")\n",
    "from convertor import convert\n",
    "from preprocessing import get_target, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T16:45:09.186056Z",
     "start_time": "2023-01-06T16:45:09.003092Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdbqIS-UWka4"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T16:45:13.740680Z",
     "start_time": "2023-01-06T16:45:13.734762Z"
    },
    "id": "Pk2w6ac8Wka5"
   },
   "outputs": [],
   "source": [
    "def df_to_fasta(df, path):\n",
    "    lines = []\n",
    "    df.apply(lambda row: lines.append(f\">{row['tag']}\\n{row['data']}\\n\"),axis=1)\n",
    "    with open(path,'w') as file:\n",
    "        file.write(''.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T16:45:14.035692Z",
     "start_time": "2023-01-06T16:45:14.026837Z"
    },
    "id": "yoDSV7bjWka6"
   },
   "outputs": [],
   "source": [
    "def fasta_to_df(path):\n",
    "    with open(path, 'r') as file:\n",
    "        text = file.read()\n",
    "    lines = [line for line in text.split('\\n') if len(line) > 0]\n",
    "    s = ''\n",
    "    tags = []\n",
    "    data = []\n",
    "    for l in lines:\n",
    "        if(l[0]=='>'):\n",
    "            tags.append(l)        \n",
    "            data.append(s)\n",
    "            s = ''\n",
    "        else:\n",
    "            s += l    \n",
    "    data.append(s)\n",
    "    df = pd.DataFrame(\n",
    "            {\n",
    "                'tag': tags,\n",
    "                'data': data[1:]\n",
    "            })\n",
    "    df['tag'] = df['tag'].apply(lambda x: x[1:])    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T16:45:14.314416Z",
     "start_time": "2023-01-06T16:45:14.309530Z"
    },
    "id": "nQOAHaVBWka_"
   },
   "outputs": [],
   "source": [
    "class DotDict(dict):\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T16:45:14.630637Z",
     "start_time": "2023-01-06T16:45:14.617140Z"
    },
    "id": "pzR6yRp8v_aT"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(validations, predictions, LABELS):            \n",
    "    freq = metrics.confusion_matrix(validations, predictions)        \n",
    "    sensitivity =  (np.divide(freq.transpose(),\n",
    "                             np.sum(freq, axis=1)).transpose() * 100).round(2)    \n",
    "    annotation = []\n",
    "    for i in range(freq.shape[0]):\n",
    "        row = []\n",
    "        for j in range(freq.shape[1]):\n",
    "            row.append(f'{freq[i][j]}\\n {sensitivity[i][j]}%')            \n",
    "        annotation.append(row)\n",
    "    annotation = np.array(annotation)\n",
    "    sns.heatmap(sensitivity, cmap=\"YlOrBr\",\n",
    "                vmin=0, vmax=100,\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=LABELS,\n",
    "                yticklabels=LABELS,\n",
    "                annot=annotation,\n",
    "               fmt=':<')    \n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.ylabel(\"Actually Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.show()            \n",
    "\n",
    "def report(pred, df, ref):\n",
    "    number_of_hit = len(df['hit seq'].unique())\n",
    "    print(f'number of unique hit: {number_of_hit}')\n",
    "    total = len(df[df['hit seq'].isin(ref['data'])]['hit seq'].unique()) \n",
    "    print(f'total mir: {total}')    \n",
    "    selected = df[pd.Series(pred).apply(lambda x: True if x==1 else False)]\n",
    "    found_seq = selected[selected['hit seq'].isin(ref['data'])]['hit seq'].unique()\n",
    "    found = len(found_seq)\n",
    "    print(f'found mir : {found}')\n",
    "    print(f'fount to all : {round(found / total * 100, 2)}%')\n",
    "    fp = len(selected[~selected['hit seq'].isin(ref['data'])]['hit seq'].unique())\n",
    "    print(f'fp: {fp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qLMRhTLWkbA"
   },
   "source": [
    "# Load all plant dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T16:49:39.594785Z",
     "start_time": "2023-01-06T16:49:39.589571Z"
    }
   },
   "outputs": [],
   "source": [
    "all_plant = [\n",
    "    \"O.sativa\",\n",
    "    \"A.thaliana\",\n",
    "    \"C.sinensis\",\n",
    "    \"Z.mays\",\n",
    "    \"T.aestivum\",\n",
    "    \"G.max\",\n",
    "    \"G.raimondii\",\n",
    "    \"M.truncatula\",\n",
    "    \"S.bicolor\",\n",
    "    #\"H.vulgare\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T17:00:10.547811Z",
     "start_time": "2023-01-06T17:00:10.539919Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../classifier/mu.pickle', 'rb') as handle:\n",
    "    mu = pickle.load(handle)\n",
    "with open('../classifier/std.pickle', 'rb') as handle:\n",
    "    std = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T16:49:39.923892Z",
     "start_time": "2023-01-06T16:49:39.914779Z"
    },
    "id": "QSvkewSupdLq"
   },
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T17:10:34.037051Z",
     "start_time": "2023-01-06T17:10:34.026042Z"
    },
    "id": "YREQVEYCQROA"
   },
   "outputs": [],
   "source": [
    "def load(plant, mu=None, std=None, under_sampling=True):\n",
    "    posX = pd.read_csv(f\"../Experiment/{plant}/positive/Result/result_level1_filter.csv\")\n",
    "    posX = convert(posX)    \n",
    "    posY = np.ones(posX.shape[0], dtype='float32')\n",
    "    posY = np_utils.to_categorical(posY, 2)\n",
    "    \n",
    "    \n",
    "    negX = pd.read_csv(f\"../Experiment/{plant}/negative/Result/result_level1_filter.csv\")\n",
    "    negX = convert(negX)    \n",
    "    negY = np.zeros(negX.shape[0], dtype='float32')\n",
    "    negY = np_utils.to_categorical(negY, 2)        \n",
    "    \n",
    "    Y = np.concatenate([posY, negY])            \n",
    "    X = pd.concat([posX, negX]).reset_index(drop=True)\n",
    "    [feature, mu, std] = preprocessing(X, mu, std)        \n",
    "    feature[\"index\"] = [*[\"p\" + str(i) for i in posX.index], *[i for i in negX.index]]\n",
    "    data[plant] = {}    \n",
    "    if(under_sampling):\n",
    "        rus = RandomUnderSampler(random_state=0)  \n",
    "        feature.columns = [str(i) for i in feature.columns]\n",
    "        feature, Y = rus.fit_resample(feature , Y)                \n",
    "        Y = np_utils.to_categorical(Y, 2)         \n",
    "    index = feature['index'][Y[:,1] == 0]    \n",
    "    return negX.iloc[index]['precursor seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T17:18:05.738724Z",
     "start_time": "2023-01-06T17:10:35.081501Z"
    }
   },
   "outputs": [],
   "source": [
    "for plant in all_plant:        \n",
    "    precursor_seq = load(plant=plant, mu=mu, std=std)    \n",
    "    fasta = \"\"\n",
    "    for i in precursor_seq.index:\n",
    "        fasta += f\">{i}\\n{precursor_seq[i]}\\n\"            \n",
    "    with open(f\"../../plantmirp2/{plant}_negative_precursor.fasta\", \"w\") as file:\n",
    "        file.write(fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "qyC8IFwrWkag",
    "bdbqIS-UWka4",
    "5Ueqwrjc5ewu",
    "Yqno44cv5iiY",
    "TlT1KSuI5mJX",
    "zKOjU6DD5oCk",
    "JNmcvnfJZhok",
    "-1L8jIc5WkbW"
   ],
   "name": "Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
